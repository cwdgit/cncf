1.install kubernetes

下载安装包
$ wget \ https://training.linuxfoundation.org/cm/LFS258/LFS258_V2018-01-16_SOLUTIONS.tar.bz2 \ --user=LFtraining --password=Penguin2014
$ tar -xvf LFS258_V2018-01-16_SOLUTIONS.tar.bz2

安装 kubernetes
ssh -i LFS458.pem student@35.226.100.87
apt-get update && apt-get upgrade -y
apt-get install -y docker.io
添加安装源
root@lfs458-node-1a0a:~# vim /etc/apt/sources.list.d/kubernetes.list
deb http://apt.kubernetes.io/ kubernetes-xenial main
添加gpg key 
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg  | apt-key add
安装kubeadm
apt-get install -y kubeadm=1.9.1-00 kubelet=1.9.1-00
下载网络插件文件：
 flannel：wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
 calico: wget https://goo.gl/eWLkzb -O calico.yaml
 修改文件中的network
 
 初始化master 安装kubernetes
 kubeadm init --pod-network-cidr 10.244.0.0/16
 
 安装flannel
 cp /root/kube-flannel.yml .
 kubectl apply -f kube-flannel.yml
 
 允许master可以允许其他的pod
  kubectl taint nodes --all node-role.kubernetes.io/master-
  kubectl describe node lfs458-node-1a0a | grep -i taint 
  
  扩展集群
  生成token ca cert hash文件
  openssl x509 -pubkey  -in /etc/kubernetes/pki/ca.crt | openssl rsa  -pubin -outform der 2>/dev/null | openssl dgst  -sha256 -hex | sed ’s/^.* //’
  
  kubeadm join --token 27eee4.6e66ff60318da929 10.128.0.3:6443 --discovery-token-ca-cert-hash sha256:6d541678b05652e1fa5d43908e75e67376e994c3483d6683f2a18673e5d2a1b
  
  kubectl get nodes
  kubectl get namespace
  
  运行一个deployment 
  kubectl run nginx --image nginx 
  kubectl get deployment
  kubectl describe deployment nginx
  kubectl get events
  kubectl get deployment nginx -o yaml
  kubectl get deployment nginx -o yaml > first.yaml
  kubectl delete deployment nginx
  kubectl create -f first.yaml
  kubectl get deployment nginx -o yaml > second.yaml
  kubectl expose deployment nginx --port=80
  kubectl get svc nginx
  kubectl describe pod nginx**************
  
  调整rc的副本数
  kubectl scale deployment nginx --replicas=3 
  kubectl get deployment nginx 
  kubectl get ep nginx
  kubectl get pod -o wide
  kubectl delete pod nginx-****
  kubectl expose deployment nginx --type=LoadBalancer 
  删除deployment
  kubectl delete deployment nginx
  kubectl delete ep nginx
  kubectl delete svc nginx
  
  resource limits
  cpu内存限制
  kubectl run hog --image vish/stress
  kubectl get deployments 
  kubectl describe deployment hog
  kubectl get deployment hog -o yaml
  
  kubectl get deployment hog -o yaml > hog.yaml
  
  
  
  hog.yaml
  imagePullPolicy: Always
    name: hog
    resources:
       limits:
         memory: "4Gi"
       requests:
         memory: "2500Mi"
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    
    namespace的资源限制
    kubectl crate namespace low-usage-limit
    
    vim low-resource-range.yaml
    apiVersion: v1
    kind: LimitRange
    metadata: 
      name: low-resource-range
    spec:
      limits:
      - default:
           cpu: 1
           memory: 500Mi
        defaultRequest:
           cpu: 0.5
           memory: 100Mi
        type: Container
        
 绑定limitrange到namespace上
 kubectl create -f low-resource-range.yaml --namespace=low-usage-limit
 kubectl get LimitRange --all-namespaces
 kubectl run limited-hog --image vish/stress -n low-usage-limit
 kubectl get deployment -n low-usage-limit
 kubectl -n low-usage-limit get pod limited-hog-2556092078-wnpnv -o yaml 
    
 spec:
   containers:
   - image: vish/stress
     imagePullPolicy: Always
     name: limited-hog
     resources:
       limits:
          cpu: "1"
          memory: 500Mi
       requests:
          cpu: "1"
          memory: 500Mi
     terminationMessagePath: /dev/termination-log
     如果没有设置namespace的资源空间，设置resource的话，服务会部署失败。
     
     配置tls访问
     查看证书和api地址
     less ~/.kube/config
     获取客户端client-cert-data key
     export client=$(grep client-cert ~/.kube/config |cut -d" " -f 6)
     export key=$(grep client-key-data ~/.kube/config |cut -d " " -f 6)
     export auth=$(grep certificate-authority-data ~/.kube/config |cut -d " " -f 6)
     echo $client | base64 -d - > ./client.pem
     echo $key | base64 -d - > ./client-key.pem
     echo $auth | base64 -d - > ./ca.pem
     kubectl config view |grep server 
     
     通过获取到的证书和API地址，进行访问。
     curl --cert ./client.pem --key ./client-key.pem --cacert ./ca.pem https://10.128.0.3:6443/api/v1/pods
  
     通过json文件创建一个新的pod
     vim curlpod.json
     {
         "kind": "Pod",
         "apiVersion": "v1",
         "metadata": {
             "name": "curlpod"，
             "namespace": "default",
             "labels": "examplepod"
             }
       },
       "spec": {
            "containers": [{
                  "name": "nginx",
                  "image": "nginx",
                  "ports":[{"containerPort":80}]
                 }]
                  }
                  }
     curl --cert ./client.pem --key ./client-key.pem --cacert ./ca.pem https://10.128.0.3:6443/api/v1/namespaces/default/pods -XPOST -H’Content-Type: application/json’ \
     -d@curlpod.json
     
     
     
      api 调用
      
      kubectl get endpoints
      
      cd /home/student/.kube/cache/discovery/
      python -m json.tool v1/serverresources.json
      
      
      
      RESTful API Access
      
      kubectl config view
      kubectl get secrets -all-namespaces
      kubectl get secrets
      kubectl describe secret default-token-jdpq7
      kubectl describe secret default-token-jdqp7 |grep ^token |cut -f7 -d ’ ’
      
      
      
      
      WORKING WITH CRON JOBS
      vim cron-job.yaml
      apiVersion: batch/v1beta1
      kind: CronJob
      metadata:
        name: date
      spec: 
        schedule: "*/1 * * * *"
        jobTemplate:
           spec:
              template:
                spec:
                   containers:
                   - name: dateperminute
                     image: busybox
                     args:
                     - /bin/sh
                     - -c
                     - date; sleep 30
                   restartPolicy: OnFailure
                   
                   
                   
      Managing state with deployment
  
      kubectl get rs
      vim rs.yaml
      apiVersion: extensisons/v1beta1
      kind: ReplicaSet
      metadata:
         name: rs-one
      spec:
         replicas: 2
         template:
           metadata:
              labels:
                 system: ReplicaOne
           spec:
              containers:
              - name: nginx
                image: nginx:1.7.9
                ports:
                - containerPort: 80
  
  kubectl create -f rs.yaml
  kubectl describe rs/rs-one
  kubectl get pods
  
  删除ReplicaSet,但是不删除pod
  kubectl delete rs/rs-one --cascade=false
  kubectl describe rs/rs-one
  kubectl get pods
  kubectl create -f rs.yaml
  kubectl get rs
  kubectl get pods
  kubectl edit pod rs-one-3c6bp
  修改label
  kubectl get po -L system
  
  
  
  
  WORKING WITH DAEMONSETS AND ROLLING UPDATES AND ROLLBACKS
  
  查看updateStrategy 设置
  kubectl get ds/ds-one o yaml | grep -A 1 Strategy
  updateStrategy:
    type: OnDelete/RollingUpdate
    
  更新镜像版本
  kubectl set image ds ds-one nginx=nginx:1.8.1-alpine
  查看运行的pod镜像版本是否更改
  kubectl describe po/ds-one-b1dcv | grep Image
  删除这个pod，查看其镜像版本，发现镜像版本更改了
  
  查看daemonset更新历史
  kubectl rollout history ds/ds-one
  kubectl rollout history ds/ds-one --revision=1
  
  撤销某次更新
  kubectl rollout undo ds/ds-one --to-revison=1
  
  当type是delete时，只有删除旧的pod才会触发更新。
  当type是rollingupdate时，修改后会立即更新。
  
  kubectl rollout history ds/ds-two --revision=2
  
  
  
  
  SERVICE
  部署一个服务
  kubectl expose deployment/nginx-one -n accounting
  配置nodeport
  kubectl expose deployment nginx-one --type=NodePort --name=service-lab -n accounting
  kubectl describe service -n accounting
  
  
  
  USE LABELS TO MANAGER RESOURCES
  kubectl label node node1 system-
  
  Volumes and Data
  
  Create a ConfigMap
  通过挂载文件实现
  mkdir primary
  echo c > primary/cyan
  echo m > primary/magenta
  echo y > primary/yellow
  echo k > primary/black
  echo "known as key" >> primary/black
  echo blue > favorite
     
  创建configmap从文件中获取变量
  kubectl create configmap colors --from-literal=text=black --from-file=./favorite --from-file=./primary/ 
  
  kubectl get configmap colors
  kubectl get configmap colors -o yaml
  
  创建pod挂载configmap中单个值
  apiVersion: v1
  kind: Pod
  metadata:
     name: shell-demo
  spec: 
      containers:
      - name: nginx
        image: nginx
        env:
        - name: ilike
          valueFrom:
             configMapKeyRef:
                name: colors
                key: favorite
             
 
 vim simpleshell.yaml
 envFrom:
 - configMapRef:
      name: colors
      
      
  通过yaml创建configmap
  apiVersion: v1
  kind: ConfigMap
  metadata:
     name: fast-car
     namespace: default
  data:
     car.make: Ford
     car.model: Mustang
     car.trim: Shelby
     
 把configmap当做一个volume进行挂载
 vim simpleshell.yaml
 spec:
    containers:
       - name: nginx
         image: nginx
         volumeMounts:
         - name: car-vol
           mountPath: /etc/cars
    volumes:
      - name: car-vol
        configMap:
           name: fast-car
 
 创建PV
 vim PVol.yaml
 apiVersion: v1
 kind: PersistentVolume
 metadata:
    name: pvvol-1
 spec:
    capacity:
    storage: 1Gi
 accessModes:
   - ReadWriteMany
 persistentVollumeReclaimPolicy: Retain
 nfs:
   path: /opt/sfw
   server: node1
   readOnly: false
   
   kubectl get pv
   
   创建pvc
   vim pvc.yaml
   apiVersion: v1
   kind: PersistentVolumeClaim
   metadata:
      name: pvc-one
   spec:
      accessModes:
      - ReadWriteMany
      resources:
        requests:
          storage: 200Mi
   
   kubectl get pvc
   创建deployment使用pvc
   apiVersion: apps/v1beta1
   kind: Deployment
   metadata:
      annotations:
        deployment.kubernetes.io/revision: "1"
      generation: 1
      labels:
        run: nginx
      name: nginx-nfs
      namespace: default
      resourceVersion: "1411"
    spec:
      replicas: 1
      selector:
        matchLabels:
           run: nginx
       strategy:
         rollingUpdate:
            maxSurge: 1
            maxUnavailable: 1
         type: RollingUpdate
       template:
         metadata:
            creationTimestamp: null
            labels:
              run: nginx
         spec:
           containers:
           - image: nginx
             imagePullPolicy: Always
             name: nginx
             volumeMounts:
             - name: nfs-vol
               mountPath: /opt
             ports：
             - containerPort: 80
               protocol: TCP
             resources: {}
             terminationMessagePath: /dev/termination-log
             terminationMessagePolicy: File
           volumes:
           - name: nfs-vol
             persistentVolumeClaim:
                claimName: pvc-one
           dnsPolicy: ClusterFirst
           restartPolicy: Always
           schedulerName: default-scheduler
           securityContext: {}
           terminationGracePeriodSeconeds: 30
    
    用resourcequota限制pvc使用
    vim storage-quota.yaml
    apiVersion: v1
    kind: ResourceQuota
    metadata:
      name: storagequota
    spec:
      hard:
        persistentvolumeclaims: "10"
        requests.storage: "500Mi"
   
将resource-quota绑定到namespace  
kubectl create -f storage-quota.yaml -n small


delete 
retain
recycle

SCHEDULING
assign pods using labels

kubectl describe nodes | grep -i label
kubectl describe nodes | grep -i taint

kubectl label nodes master2 status=vip
kubectl label nodes master3 status=other
kubectl get nodes --show-labels

apiVersion: v1
kind: Pod
metadata:
  name: vip
spec:
  containers:
  - name: vip
    image: busybox
    args:
    - sleep
    - "1000000"
  - name: vip2
    image: busybox
    args:
    - sleep
    - "1000000"
  - name: vip3
    image: busybox
    args:
    - sleep
    - "1000000"
  nodeSelector:
    status: vip
 
 使用taints去控制pod部署

 apiVersion: apps/v1beta1
 kind: Deployment
 metadata:
   name: taint-deployment
 spec:
   replicas: 8
   template: 
     metadata:
       labels:
         app: nginx
     spec:
       containers:
       - name: nginx
         image: nginx:1.7.9
         ports:
         - containerPort: 80
           
设置master节点不可调度（taint）
kubectl taint nodes tvm-04 node-role.kubernetes.io/master=:NoSchedule
   
查看node的role
kubectl describe nodes master1 |grep -E '(Roles|Taints)'
   
设置master可以部署相关服务
apiVersion: apps/v1 # for versions before 1.9.0 use apps/v1beta2
kind: Deployment
metadata:
  name: whoami-t2
  labels:
    app: whoami
spec:
  replicas: 3
  selector:
    matchLabels:
      app: whoami
  template:
    metadata:
      labels:
        app: whoami
    spec:
      containers:
        - name: whoami
          image: opera443399/whoami:0.9
          ports:
            - containerPort: 80
      tolerations:
      - key: "node-role.kubernetes.io/master"
        operator: "Equal"
        value: ""
        effect: "NoSchedule"
  
  
 Review log file locations
 review log file locations
 查看kubelet日志
 journalctl -u kubelet 
 
 /var/log/kube-apiserver.log
 /var/log/kube-scheduler.log
 /var/log/kube-controller-manager.log
 
 viewing logs output
 kubectl get pod --all-namespaces
 kubectl logs kube-scheduler-lfs458-node -n kube-system | grep nginx
 
 create a custom resource definition
 crd.yaml

 apiVersion: apiextensions.k8s.io/v1beta1
 kind: CustomResourceDefinition
 metadata:
    name: crontabs.training.lfs458.com
 spec:
    scope: Cluster
    group: training.lfs458.com
    version: v1
    names: 
       kind: CronTab
       plural: crontabs
       
 kubernetes federation 
 
 安装Helm
 
wget https://storage. googleapis.com/kubernetes-helm/helm-v2.7.0-linux-amd64.tar.gz
wget goo.gl/nbEcHn
tar -xvf nbEcHn
sudo cp linux-amd64/helm /usr/local/bin/

kubectl create serviceaccount --namespace kube-system tiller
kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller

helm init

kubectl patch deployment tiller-deploy -p ’{"spec":{"template":{"spec":{"serviceAccount":"tiller"}}}}’ -n kube-system

helm help
helm home


  
  
  
  
  
  
  
  
  
